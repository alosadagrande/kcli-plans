This repo is a POC of deploying ocp4 using an hybrid approach between upi and ipi, and by heavily leveraging kcli.

The initial target for this work is ovirt/rhev and libvirt although the approach aims to be independant of the platform.

The main features are:

- be able to deploy ocp using minimal infrastructure requirements.
- we assume that there is no control over dns and pxe that would facilitate use of UPI out of the box.
- Multiple clusters can live on the same network.
- The procedure is exactly the same for libvirt or ovirt.


## requirements

- openshift-install binary needs to be installed
- kcli needs to be installed ( and with support for the target platform, so by using container or pip if deploying on something else than libvirt)
- The target platform needs:
  - a rhcos image ( *kcli download rhcosootpa* )
  - a centos image ( *kcli download centos7* )
- The target platform needs to have ignition support. 
  
  For ovirt/rhv, this either requires ovirt >= 4.3.4 or to install [an additional vdsm hook](https://gerrit.ovirt.org/#/c/100008), along with the custom property *ignitiondata*

  Other potential platforms like openstack or gcp already have support for ignition.

  Kubevirt also has experimental ignition support (provided by *yours truly*, btw)

## How to Use

### Define your variables

create an *env.sh* file to set:

- cluster name
- domain name
- number of masters
- number of workers
- masters memory
- workers memory
- bootstrap memory
- haproxy memory
- default disk size
- extra disk size for secondary disk ( to use with rook, for instance)
- whether to create a bridge on top of the nics of the nodes (useful if deploying for kubevirt)

look at [*env.sh.sample*(env.sh.sample)] as reference

### Deploy

`./ocp.sh`

## architecture

We deploy :

- an arbitrary number of masters.
- an arbitrary number of workers.
- an haproxy node, also used as dns server for both masters and workers.
- a bootstrap node.

We first generate all the ignition files needed for the install.

As rhcos lacks an agent that would report ip, we do a temporary deployment using a centos7 template, for all the masters, workers, bootstrap and haproxy node.

The goal of this first iteration is to gather ips and macs for all those nodes.

With this information, a kcli parameter file is created and stored in the same directory than the openshift artifacts for the given cluster.

We then delete the temporary deployment and launch the final one, where we make sure each node has the proper mac address ( and as such gets the same ip).

Haproxy configuration and dns entries are created on the fly on the haproxy node, which also serves as a web server for some additional ignition files needed on the nodes and which can't get injected ( they are generated on the bootstrap node).

Also note that for bootstrap, masters and workers nodes, we merge the ignition data generated by the openshift installer with the ones generated by kcli, in particular we force dns server on those nodes to point to our haproxy node.
